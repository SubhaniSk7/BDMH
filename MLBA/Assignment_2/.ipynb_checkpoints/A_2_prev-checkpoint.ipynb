{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy,pickle,glob\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc,f1_score,precision_score,recall_score,precision_recall_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(samples, labels, test_size):\n",
    "#     return train_test_split(samples, labels,stratify=labels, test_size=test_size,random_state=45)\n",
    "    return train_test_split(samples, labels,test_size=test_size,random_state=40)\n",
    "\n",
    "def draw_confusion_matrix(y_actual, y_predicted):\n",
    "    cm=confusion_matrix(y_actual, y_predicted)\n",
    "    labels = ['POsivite', 'Negative']\n",
    "    no_of_labels = 2\n",
    "    print(\"\\nConfusion matrix : \")\n",
    "    x = PrettyTable()\n",
    "    print(\"                   Predicted labels →\")\n",
    "    x.field_names = [\"Actual labels ↓\"] + [str(labels[i]) for i in range(no_of_labels)]\n",
    "    for i in range(no_of_labels):\n",
    "        ls = [(str(labels[i]))] + list(cm[i])\n",
    "        x.add_row(ls)\n",
    "    print(x) \n",
    "\n",
    "def draw_roc(y_actual, scores, title=''):\n",
    "    fpr, tpr, thresholds = roc_curve(y_actual, scores, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr,tpr, label = 'AUC: '+str(round(roc_auc, 4)))\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('1-Specificity = FPR')\n",
    "    plt.ylabel(\"Sensitivity = TPR = Recall\")\n",
    "    plt.title(\"AUC-ROC Curve: \" + title)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.savefig(title+'-ROC')\n",
    "    plt.show()\n",
    "    \n",
    "def metric(y_test, y_pred,scores, title=''):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn /(tn + fp)\n",
    "    sensitivity = tp/(tp + fn)\n",
    "    precision = tp/(tp + fp)\n",
    "    f1 = (precision * sensitivity * 2) / (precision + sensitivity)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    npv = tn/(tn + fn)\n",
    "    fpr = fp/(fp + tn)\n",
    "    rmc = 1.0 - acc\n",
    "    x = PrettyTable()\n",
    "    metr_list = []\n",
    "    x.field_names = [\"Evaluation Metric\", \"Score\"]\n",
    "    x.add_row([\"Accuracy\", round(acc, 4)])\n",
    "    metr_list.append(round(acc, 4))\n",
    "    x.add_row([\"Specificity\", round(specificity, 4)])\n",
    "    metr_list.append(round(specificity, 4))\n",
    "    x.add_row([\"Sensitivity\", round(sensitivity, 4)])\n",
    "    metr_list.append(round(sensitivity, 4))\n",
    "    x.add_row([\"Precision\", round(precision, 4)])\n",
    "    metr_list.append(round(precision, 4))\n",
    "    x.add_row([\"NPV\", round(npv, 4)])\n",
    "    metr_list.append(round(npv, 4))\n",
    "    x.add_row([\"FPR\", round(fpr, 4)])\n",
    "    metr_list.append(round(fpr, 4))\n",
    "    x.add_row([\"RMC\", round(rmc, 4)])\n",
    "    metr_list.append(round(rmc, 4))\n",
    "    x.add_row([\"F1 score\", round(f1, 4)])\n",
    "    metr_list.append(round(f1, 4))\n",
    "    print(x)\n",
    "    draw_confusion_matrix(y_test, y_pred)\n",
    "    draw_roc(y_test,scores, title)\n",
    "    print('--------------------------------------------------------------\\n\\n')\n",
    "    return metr_list\n",
    "\n",
    "def rc(clfs, dt, lbel, names):\n",
    "    data = copy.deepcopy(dt)\n",
    "    label = copy.deepcopy(lbel)\n",
    "    nfpr = []\n",
    "    ntpr = []\n",
    "    pfpr = []\n",
    "    ptpr = []\n",
    "    label[label == 1] = 2\n",
    "    label[label == 0] = 1\n",
    "    neg_lbl = copy.deepcopy(label)\n",
    "    pos_lbl = copy.deepcopy(label)\n",
    "    neg_lbl[neg_lbl == 1] = 1 \n",
    "    neg_lbl[neg_lbl == 2] = 0\n",
    "    pos_lbl[pos_lbl == 1] = 0\n",
    "    pos_lbl[pos_lbl == 2] = 1\n",
    "    for i in range(len(clfs)):\n",
    "        prob = clfs[i].predict_proba(data)\n",
    "        negatives = prob[:,:1]\n",
    "        positives = prob[:,1:]\n",
    "        fpr, tpr, thresholds = roc_curve(neg_lbl, negatives, pos_label=None)\n",
    "        nfpr.append(fpr)\n",
    "        ntpr.append(tpr)\n",
    "        fpr, tpr, thresholds = roc_curve(pos_lbl, positives, pos_label=None)\n",
    "        pfpr.append(fpr)\n",
    "        ptpr.append(tpr)\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        plt.plot(nfpr[i], ntpr[i], label = names[i])\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlabel(\"True Positive Rate\")\n",
    "    plt.ylabel(\"False Positive Rate\")\n",
    "    plt.title('Negative Class All Models ROC curves')\n",
    "    plt.savefig('Negative_Class-ROC')\n",
    "    plt.show()\n",
    "    for i in range(len(names)):\n",
    "        plt.plot(pfpr[i], ptpr[i], label = names[i])\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlabel(\"True Positive Rate\")\n",
    "    plt.ylabel(\"False Positive Rate\")\n",
    "    plt.title('Positive Class All Models ROC curves')\n",
    "    plt.savefig('Positive_Class-ROC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train_X, test_X):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_X_train = pd.read_csv('outputs/A/MT18117_q1_complete_X_train.csv')\n",
    "complete_X_test = pd.read_csv('outputs/A/MT18117_q1_complete_X_test.csv')\n",
    "complete_Y_train = pd.read_csv('outputs/A/MT18117_q1_complete_Y_train.csv',names=['Group'])\n",
    "complete_Y_test = pd.read_csv('outputs/A/MT18117_q1_complete_Y_test.csv',names=['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((237, 29459), (103, 29459), (237, 1), (103, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_X_train.shape, complete_X_test.shape, complete_Y_train.shape, complete_Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = complete_X_train.values\n",
    "X_test = complete_X_test.values\n",
    "y_train = complete_Y_train.values\n",
    "y_test = complete_Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((237, 29459), (103, 29459), (237, 1), (103, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale = scale(X_train)\n",
    "X_test_scale = scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algo with Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression(solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(estimator,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=5,\n",
    "                                  n_population=50,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=40,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.05,\n",
    "                                  tournament_size=3,\n",
    "                                  n_gen_no_change=10,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                  \tstd                      \tmin              \tmax              \n",
      "0  \t50    \t[-10000.    14707.06]\t[ 0.         94.33120587]\t[-10000.  14488.]\t[-10000.  14944.]\n",
      "1  \t33    \t[-10000.    14616.12]\t[ 0.         80.31130431]\t[-10000.  14459.]\t[-10000.  14804.]\n",
      "2  \t38    \t[-10000.    14537.46]\t[ 0.         56.93301678]\t[-10000.  14421.]\t[-10000.  14679.]\n",
      "3  \t29    \t[-10000.    14492.22]\t[ 0.         63.73108818]\t[-10000.  14276.]\t[-10000.  14655.]\n",
      "4  \t27    \t[-10000.  14451.]    \t[ 0.         53.72559911]\t[-10000.  14276.]\t[-10000.  14586.]\n",
      "5  \t25    \t[-10000.    14407.86]\t[ 0.         57.55519438]\t[-10000.  14276.]\t[-10000.  14570.]\n",
      "6  \t28    \t[-10000.    14369.48]\t[ 0.         51.74716997]\t[-10000.  14244.]\t[-10000.  14514.]\n",
      "7  \t35    \t[-10000.    14347.92]\t[ 0.         54.82438873]\t[-10000.  14208.]\t[-10000.  14516.]\n",
      "8  \t33    \t[-10000.    14314.76]\t[ 0.        50.0130223]  \t[-10000.  14202.]\t[-10000.  14461.]\n",
      "9  \t29    \t[-10000.   14288.1]  \t[ 0.         49.12809787]\t[-10000.  14202.]\t[-10000.  14424.]\n",
      "10 \t24    \t[-10000.   14240.2]  \t[ 0.         33.24093861]\t[-10000.  14174.]\t[-10000.  14325.]\n",
      "11 \t23    \t[-10000.   14219.7]  \t[ 0.         34.45301148]\t[-10000.  14158.]\t[-10000.  14339.]\n",
      "12 \t23    \t[-10000.    14201.74]\t[ 0.         32.10907037]\t[-10000.  14131.]\t[-10000.  14313.]\n",
      "13 \t30    \t[-10000.    14194.16]\t[ 0.         41.96634842]\t[-10000.  14089.]\t[-10000.  14302.]\n",
      "14 \t33    \t[-10000.    14164.38]\t[ 0.         45.15479598]\t[-10000.  14064.]\t[-10000.  14271.]\n",
      "15 \t33    \t[-10000.    14140.36]\t[ 0.         55.87942734]\t[-10000.  13965.]\t[-10000.  14262.]\n",
      "16 \t34    \t[-10000.   14110.3]  \t[ 0.         54.94442647]\t[-10000.  13972.]\t[-10000.  14225.]\n",
      "17 \t27    \t[-10000.    14077.72]\t[ 0.         46.39398237]\t[-10000.  13972.]\t[-10000.  14206.]\n",
      "18 \t37    \t[-10000.    14057.82]\t[ 0.         55.53582267]\t[-10000.  13969.]\t[-10000.  14208.]\n",
      "19 \t31    \t[-10000.   14023.4]  \t[ 0.         49.09908349]\t[-10000.  13915.]\t[-10000.  14173.]\n",
      "20 \t30    \t[-10000.   13989.5]  \t[ 0.         44.47437464]\t[-10000.  13894.]\t[-10000.  14145.]\n",
      "21 \t35    \t[-10000.    13966.14]\t[ 0.         47.24574478]\t[-10000.  13870.]\t[-10000.  14089.]\n",
      "22 \t32    \t[-10000.   13951.7]  \t[ 0.         49.87875299]\t[-10000.  13854.]\t[-10000.  14053.]\n",
      "23 \t34    \t[-10000.    13931.76]\t[ 0.         50.04260585]\t[-10000.  13854.]\t[-10000.  14076.]\n",
      "24 \t33    \t[-10000.    13900.52]\t[ 0.         37.63521755]\t[-10000.  13844.]\t[-10000.  14033.]\n",
      "25 \t28    \t[-10000.    13880.38]\t[ 0.         40.26059612]\t[-10000.  13800.]\t[-10000.  14024.]\n",
      "26 \t27    \t[-10000.    13863.66]\t[ 0.         37.92445649]\t[-10000.  13788.]\t[-10000.  13986.]\n",
      "27 \t34    \t[-10000.    13852.32]\t[ 0.         50.24676706]\t[-10000.  13788.]\t[-10000.  14018.]\n",
      "28 \t34    \t[-10000.   13838.4]  \t[ 0.         47.75437153]\t[-10000.  13769.]\t[-10000.  13957.]\n",
      "29 \t25    \t[-10000.    13825.16]\t[ 0.         50.52102928]\t[-10000.  13726.]\t[-10000.  13954.]\n",
      "30 \t27    \t[-10000.    13804.46]\t[ 0.         50.40643213]\t[-10000.  13719.]\t[-10000.  13966.]\n",
      "31 \t31    \t[-10000.    13785.66]\t[ 0.         54.75166116]\t[-10000.  13711.]\t[-10000.  13923.]\n",
      "32 \t31    \t[-10000.    13766.48]\t[ 0.         43.30830867]\t[-10000.  13674.]\t[-10000.  13883.]\n",
      "33 \t29    \t[-10000.    13738.92]\t[ 0.         40.59942857]\t[-10000.  13674.]\t[-10000.  13883.]\n",
      "34 \t33    \t[-10000.    13736.58]\t[ 0.         58.50746619]\t[-10000.  13654.]\t[-10000.  13917.]\n",
      "35 \t29    \t[-10000.    13709.14]\t[ 0.         48.54359278]\t[-10000.  13642.]\t[-10000.  13886.]\n",
      "36 \t28    \t[-10000.   13702.4]  \t[ 0.         53.75611593]\t[-10000.  13638.]\t[-10000.  13862.]\n",
      "37 \t32    \t[-10000.   13683.8]  \t[ 0.         44.82900847]\t[-10000.  13619.]\t[-10000.  13796.]\n",
      "38 \t34    \t[-10000.  13676.]    \t[ 0.        47.9049058]  \t[-10000.  13606.]\t[-10000.  13822.]\n",
      "39 \t24    \t[-10000.    13657.62]\t[ 0.         50.69946351]\t[-10000.  13597.]\t[-10000.  13854.]\n",
      "40 \t36    \t[-10000.    13650.02]\t[ 0.         56.29546696]\t[-10000.  13595.]\t[-10000.  13819.]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = selector.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8155339805825242"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_score(y_test, y_pred, pos_label='sPTD')\n",
    "\n",
    "recall_score(y_test, y_pred, pos_label='sPTD')\n",
    "\n",
    "precision_score(y_test, y_pred, pos_label='sPTD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13595"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(selector.support_))\n",
    "selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(selector.support_)):\n",
    "    if(selector.support_[i]==True):\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(indices, 'Features.sav')\n",
    "\n",
    "# features = joblib.load('Features.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new_complete_train = complete_X_train.iloc[:,indices]\n",
    "# X_new_complete_test = complete_X_test.iloc[:,indices]\n",
    "\n",
    "# X_new_train = X_new_complete_train.values\n",
    "# X_new_test = X_new_complete_test.values\n",
    "\n",
    "# X_new_train_scale = scale(X_new_train)\n",
    "# X_new_test_scale = scale(X_new_test)\n",
    "\n",
    "estimator = estimator.fit(X_new_complete_train, y_train)\n",
    "pred = estimator.predict(X_new_complete_test)\n",
    "\n",
    "accuracy_score(y_test, pred)\n",
    "# precision_score(y_test, pred,pos_label='sPTD')\n",
    "# recall_score(y_test, pred, pos_label='sPTD')\n",
    "# f1_score(y_test, svm_pred,pos_label='sPTD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "logistic = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'f1', cv=5,n_jobs=-1)\n",
    "# print(cross_val_score(logistic, X_train_scale, y_train, cv=10))\n",
    "logistic.fit(X_train, y_train)\n",
    "y_pred = logistic.predict(X_test)\n",
    "scores=logistic.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Reults for Logistics regression -')\n",
    "metr_list = metric(y_test, y_pred, scores, 'Logistics regression')\n",
    "common_metr_table.append(metr_list)\n",
    "metr_table_field_names.append('Log regr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 10,100,1000]\n",
    "gammas = [0.0001,0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "rbfsvm = GridSearchCV(svm.SVC(kernel='rbf',probability=True), param_grid, cv=5)\n",
    "rbfsvm.fit(X_train_scale, y_train)\n",
    "y_pred = rbfsvm.predict(X_test_scale)\n",
    "scores=rbfsvm.predict_proba(X_test_scale)[:,1]\n",
    "print('Reults for SVM classifier -')\n",
    "metr_list = metric(y_test, y_pred, scores, 'SVM')\n",
    "common_metr_table.append(metr_list)\n",
    "metr_table_field_names.append('SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = np.linspace(1, 32, 32, endpoint=True)\n",
    "min_split = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "min_samples_lef = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "max_feat = list(range(1,X_train.shape[1]))\n",
    "param_grid = {'max_depth': depth, 'min_samples_split' : min_split,'min_samples_leaf' : min_samples_lef,'max_features' : max_feat}\n",
    "dtree = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5,n_jobs=-1)\n",
    "dtree.fit(X_train, y_train)\n",
    "y_pred = dtree.predict(X_test)\n",
    "scores=dtree.predict_proba(X_test)[:,1]\n",
    "print('Reults for Decision Tree classifier -')\n",
    "metr_list = metric(y_test, y_pred, scores, 'Decision Tree')\n",
    "common_metr_table.append(metr_list)\n",
    "metr_table_field_names.append('Dec Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3,2), random_state=1)\n",
    "# print(cross_val_score(mlp, X_train, y_train, cv=10))\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "scores=mlp.predict_proba(X_test)[:,1]\n",
    "print('Reults for MultiLayer Perceptron classifier -')\n",
    "metr_list = metric(y_test, y_pred,scores, 'MultiLayer Perceptron')\n",
    "common_metr_table.append(metr_list)\n",
    "metr_table_field_names.append('ANN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth = np.linspace(1, 32, 32, endpoint=True)\n",
    "# min_split = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "# min_samples_lef = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "# est = [20,21,22,23,24,25,26]\n",
    "# param_grid = {'n_estimators' : est,'max_depth': depth, 'min_samples_split' : min_split,'min_samples_leaf' : min_samples_lef}\n",
    "\n",
    "# rf = GridSearchCV(RandomForestClassifier(), param_grid, cv=2,n_jobs=-1)\n",
    "# rf.fit(X_train_scale, y_train)\n",
    "\n",
    "# y_pred = rf.predict(X_train_scale)\n",
    "# accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
